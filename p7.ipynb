{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FjGfkEl9IRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "50e46fd0-3fb6-475f-959b-03d5a4128ccd"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "REBUILD_DATA = False # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Running on the CPU\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    TESTING = \"PetImages/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot vector\n",
        "    \n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "                            \n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # just run the init of parent class (nn.Module)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
        "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
        "\n",
        "    def convs(self, x):\n",
        "        # max pooling over 2x2\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
        "        return F.softmax(x, dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Net(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=512, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=2, bias=True)\n)\n24946\n"
        }
      ],
      "source": [
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()\n",
        "training_data_filename = \"training_data.npy\"\n",
        "# training_data_filename = \"/content/drive/My Drive/Colab Notebooks/learn_pytorch/training_data.npy\" #for running on google colab notebooks\n",
        "training_data = np.load(training_data_filename,allow_pickle=True)\n",
        "print(len(training_data))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 3\n",
        "\n",
        "\n",
        "def train(net):\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            net.zero_grad()\n",
        "\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()    # Does the update\n",
        "\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "\n",
        "def test(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i in tqdm(range(0, len(test_X), BATCH_SIZE)):\n",
        "\n",
        "      batch_X = test_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
        "      batch_y = test_y[i:i+BATCH_SIZE].to(device)\n",
        "      batch_out = net(batch_X)\n",
        "\n",
        "      out_maxes = [torch.argmax(i) for i in batch_out]\n",
        "      target_maxes = [torch.argmax(i) for i in batch_y]\n",
        "      for i,j in zip(out_maxes, target_maxes):\n",
        "          if i == j:\n",
        "              correct += 1\n",
        "          total += 1\n",
        "  print(\"Accuracy: \", round(correct/total, 3))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zCnzSAaATZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2229fd11-5f71-4559-887c-6add394c3112"
      },
      "source": [
        "train(net)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 225/225 [01:23<00:00,  2.69it/s]\n  0%|          | 0/225 [00:00<?, ?it/s]Epoch: 0. Loss: 0.2552282512187958\n100%|██████████| 225/225 [01:24<00:00,  2.67it/s]\n  0%|          | 0/225 [00:00<?, ?it/s]Epoch: 1. Loss: 0.21765998005867004\n100%|██████████| 225/225 [01:36<00:00,  2.34it/s]Epoch: 2. Loss: 0.18235094845294952\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL9QRXOCARnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3fd8b741-e4a8-4c15-c2b8-104a04c38b45"
      },
      "source": [
        "test_X.to(device)\n",
        "test_y.to(device)\n",
        "\n",
        "test(net)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 25/25 [00:04<00:00,  6.17it/s]Accuracy:  0.721\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYntCvuVAc4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "p7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}